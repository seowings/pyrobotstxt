<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Faisal Shahzad" /><link rel="canonical" href="https://pyrobotstxt.pages.dev/robotstxt/" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>RobotsTxt - pyrobotstxt</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../assets/_mkdocstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "RobotsTxt";
        var mkdocs_page_input_path = "robotstxt.md";
        var mkdocs_page_url = "/robotstxt/";
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> pyrobotstxt
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../tutorial/">User Tutorial</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../developers/">Developer Tutorial</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">API</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../imageasascii/">ImageAsASCII</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="./">RobotsTxt</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#pyrobotstxt.RobotsTxt">RobotsTxt</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#pyrobotstxt.RobotsTxt.__init__">__init__()</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#pyrobotstxt.RobotsTxt.add_user_agent">add_user_agent()</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#pyrobotstxt.RobotsTxt.include_footer">include_footer()</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#pyrobotstxt.RobotsTxt.include_header">include_header()</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#pyrobotstxt.RobotsTxt.include_image">include_image()</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#pyrobotstxt.RobotsTxt.read">read()</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#pyrobotstxt.RobotsTxt.remove_user_agent">remove_user_agent()</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#pyrobotstxt.RobotsTxt.robots_details">robots_details()</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#pyrobotstxt.RobotsTxt.robots_name">robots_name()</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#pyrobotstxt.RobotsTxt.write">write()</a>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../useragent/">UserAgent</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">pyrobotstxt</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">API</li>
      <li class="breadcrumb-item active">RobotsTxt</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/serpwings/pyrobotstxt/blob/main/docs/robotstxt.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="robotstxt-class">RobotsTxt Class<a class="headerlink" href="#robotstxt-class" title="Permanent link">&para;</a></h1>


<div class="doc doc-object doc-class">



<a id="pyrobotstxt.RobotsTxt"></a>
  <div class="doc doc-contents first">


            <details class="quote">
              <summary>Source code in <code>pyrobotstxt/__init__.py</code></summary>
              <pre class="codehilite"><code class="language-python">class RobotsTxt:
    def __init__(self, version=""):
        """Intializes Robots.txt operations

        Args:
            version (str, optional): Version number (optional) for robots.txt. Defaults to "".
        """
        self.user_agents = []
        self.create_time = datetime.now()
        self.version = version
        self.image_branding = None
        self.header = ""  # message added to the start of the output file.
        self.footer = ""  # message added to the end of the output file.

    def read(self, robots_url):
        """Read a Remote Robots.txt file from a given URL

        If robots_txt is missing a robots.txt file extention then it will be automatically added.
        Parsing will only be carried out if robots_url returns a valid response object.

        Args:
            robots_url (str):  robots.txt url at a remote location.
        """

        self.create_time = datetime.now()
        robots_url = get_corrected_url(robots_url, "")
        response = get_remote_content(robots_url)

        if response.status_code &lt; 400:
            for ua_item in response.text.split("User-agent:"):
                if ua_item:
                    ua_content_items = [
                        ua_split_item.strip()
                        for ua_split_item in ua_item.split("\n")
                        if ua_split_item
                    ]
                    if not ua_content_items[0].startswith("#"):
                        ua = UserAgent(ua_name=ua_content_items[0])
                        ua.add_allow(
                            [
                                it.split("Allow:")[-1]
                                for it in ua_content_items[1:]
                                if it.startswith("Allow:")
                            ]
                        )
                        ua.add_disallow(
                            [
                                it.split("Disallow:")[-1]
                                for it in ua_content_items[1:]
                                if it.startswith("Disallow:")
                            ]
                        )
                        # TODO: Comments are not included Yet
                        comment = [
                            it.split("# ")[-1]
                            for it in ua_content_items[1:]
                            if it.startswith("#")
                        ]

                        self.add_user_agent(ua=ua)

    def write(self, file_path="robots.txt"):
        """write robots.txt file at a given file_path location.

        Args:
            file_path (str, optional): location of robots.txt file. Defaults to "robots.txt".
        """

        with open(file_path, "w") as f:
            # include header
            if self.header:
                f.write(f"# {self.header}")

            # include user agents with consolidate text
            for ua in self.user_agents:
                ua.consolidate()
                f.write(ua.content)

            f.write("\n")

            # append ascii image, if available
            if self.image_branding:
                f.write(self.image_branding)

            # append footer message
            if self.footer:
                f.write(f"\n# {self.footer}")

    def include_header(self, message="", append_date=True):
        """include header message with/without creation date.

        Args:
            message (str, optional): header or header message. Defaults to "".
            append_date (bool, optional): Append date/time to the header. Defaults to True.
        """

        self.header = message

        if append_date:
            self.header += f"\n# Created on {self.create_time} using pyrobotstxt"

    def include_footer(self, message=""):
        """include footer message

        Args:
            message (str, optional): footer message. Defaults to "".
        """
        self.footer = message

    def include_image(self, image_path=None, desired_width=90):
        """includes ascii image provided at image_file

        Args:
            image_path (str): location of image file. Defaults to None.
            desired_width (int, optional): desired width of ASCII image. Defaults to 90(chars).
        """
        img = ImageAsASCII(image_path=image_path, desired_width=desired_width)
        img.map_to_ascii()
        self.image_branding = img.ascii_image

    def add_user_agent(self, ua):
        """Add/Append user agent to RobotsTxt

        Args:
            ua (UserAgent): user agent to be included in final robots.txt file.
        """
        self.user_agents.append(ua)

    def remove_user_agent(self, ua_name=""):
        """Remove user agent from RobotsTxt

        Args:
            ua_name (UserAgent): user agent to be removed from already included in robots.txt file.
        """
        self.user_agents -= [ua for ua in self.user_agents if ua.name == ua_name]

    @staticmethod
    def robots_name(crawl_bot):
        """Find robot name, if you know any keywrod about that crawl bot.

        Args:
            crawl_bot (str): description about the crawl bot. e.g. facebook

        Returns:
            (dict): all matching crawl bots with relevent information
        """
        return {
            robot: ROBOTS[robot]
            for robot in ROBOTS
            if crawl_bot.capitalize() in ROBOTS[robot]
        }

    @staticmethod
    def robots_details(crawl_bot):
        """Static Method to return details about any crawl bot.

        Args:
            crawl_bot (str): name of crawl bot

        Returns:
            (dict): information about all crawl bots matching to input string.
        """
        return {
            robot: ROBOTS[robot]
            for robot in ROBOTS
            if crawl_bot.lower() == robot.lower()
        }</code></pre>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h2 id="pyrobotstxt.RobotsTxt.__init__" class="doc doc-heading">
          <code class=" language-python">__init__(version='')</code>

<a href="#pyrobotstxt.RobotsTxt.__init__" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Intializes Robots.txt operations</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>version</code></b>
                  (<code>str</code>, default:
                      <code>&#39;&#39;</code>
)
              –
              <div class="doc-md-description">
                <p>Version number (optional) for robots.txt. Defaults to &ldquo;&rdquo;.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary> <code>pyrobotstxt/__init__.py</code></summary>
            <pre class="codehilite"><code class="language-python">def __init__(self, version=""):
    """Intializes Robots.txt operations

    Args:
        version (str, optional): Version number (optional) for robots.txt. Defaults to "".
    """
    self.user_agents = []
    self.create_time = datetime.now()
    self.version = version
    self.image_branding = None
    self.header = ""  # message added to the start of the output file.
    self.footer = ""  # message added to the end of the output file.</code></pre>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="pyrobotstxt.RobotsTxt.add_user_agent" class="doc doc-heading">
          <code class=" language-python">add_user_agent(ua)</code>

<a href="#pyrobotstxt.RobotsTxt.add_user_agent" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Add/Append user agent to RobotsTxt</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>ua</code></b>
                  (<code><a class="autorefs autorefs-internal" title="pyrobotstxt.UserAgent" href="../useragent/#pyrobotstxt.UserAgent">UserAgent</a></code>)
              –
              <div class="doc-md-description">
                <p>user agent to be included in final robots.txt file.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary> <code>pyrobotstxt/__init__.py</code></summary>
            <pre class="codehilite"><code class="language-python">def add_user_agent(self, ua):
    """Add/Append user agent to RobotsTxt

    Args:
        ua (UserAgent): user agent to be included in final robots.txt file.
    """
    self.user_agents.append(ua)</code></pre>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="pyrobotstxt.RobotsTxt.include_footer" class="doc doc-heading">
          <code class=" language-python">include_footer(message='')</code>

<a href="#pyrobotstxt.RobotsTxt.include_footer" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>include footer message</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>message</code></b>
                  (<code>str</code>, default:
                      <code>&#39;&#39;</code>
)
              –
              <div class="doc-md-description">
                <p>footer message. Defaults to &ldquo;&rdquo;.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary> <code>pyrobotstxt/__init__.py</code></summary>
            <pre class="codehilite"><code class="language-python">def include_footer(self, message=""):
    """include footer message

    Args:
        message (str, optional): footer message. Defaults to "".
    """
    self.footer = message</code></pre>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="pyrobotstxt.RobotsTxt.include_header" class="doc doc-heading">
          <code class=" language-python">include_header(message='', append_date=True)</code>

<a href="#pyrobotstxt.RobotsTxt.include_header" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>include header message with/without creation date.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>message</code></b>
                  (<code>str</code>, default:
                      <code>&#39;&#39;</code>
)
              –
              <div class="doc-md-description">
                <p>header or header message. Defaults to &ldquo;&rdquo;.</p>
              </div>
            </li>
            <li>
              <b><code>append_date</code></b>
                  (<code>bool</code>, default:
                      <code>True</code>
)
              –
              <div class="doc-md-description">
                <p>Append date/time to the header. Defaults to True.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary> <code>pyrobotstxt/__init__.py</code></summary>
            <pre class="codehilite"><code class="language-python">def include_header(self, message="", append_date=True):
    """include header message with/without creation date.

    Args:
        message (str, optional): header or header message. Defaults to "".
        append_date (bool, optional): Append date/time to the header. Defaults to True.
    """

    self.header = message

    if append_date:
        self.header += f"\n# Created on {self.create_time} using pyrobotstxt"</code></pre>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="pyrobotstxt.RobotsTxt.include_image" class="doc doc-heading">
          <code class=" language-python">include_image(image_path=None, desired_width=90)</code>

<a href="#pyrobotstxt.RobotsTxt.include_image" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>includes ascii image provided at image_file</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>image_path</code></b>
                  (<code>str</code>, default:
                      <code>None</code>
)
              –
              <div class="doc-md-description">
                <p>location of image file. Defaults to None.</p>
              </div>
            </li>
            <li>
              <b><code>desired_width</code></b>
                  (<code>int</code>, default:
                      <code>90</code>
)
              –
              <div class="doc-md-description">
                <p>desired width of ASCII image. Defaults to 90(chars).</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary> <code>pyrobotstxt/__init__.py</code></summary>
            <pre class="codehilite"><code class="language-python">def include_image(self, image_path=None, desired_width=90):
    """includes ascii image provided at image_file

    Args:
        image_path (str): location of image file. Defaults to None.
        desired_width (int, optional): desired width of ASCII image. Defaults to 90(chars).
    """
    img = ImageAsASCII(image_path=image_path, desired_width=desired_width)
    img.map_to_ascii()
    self.image_branding = img.ascii_image</code></pre>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="pyrobotstxt.RobotsTxt.read" class="doc doc-heading">
          <code class=" language-python">read(robots_url)</code>

<a href="#pyrobotstxt.RobotsTxt.read" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Read a Remote Robots.txt file from a given URL</p>
<p>If robots_txt is missing a robots.txt file extention then it will be automatically added.
Parsing will only be carried out if robots_url returns a valid response object.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>robots_url</code></b>
                  (<code>str</code>)
              –
              <div class="doc-md-description">
                <p>robots.txt url at a remote location.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary> <code>pyrobotstxt/__init__.py</code></summary>
            <pre class="codehilite"><code class="language-python">def read(self, robots_url):
    """Read a Remote Robots.txt file from a given URL

    If robots_txt is missing a robots.txt file extention then it will be automatically added.
    Parsing will only be carried out if robots_url returns a valid response object.

    Args:
        robots_url (str):  robots.txt url at a remote location.
    """

    self.create_time = datetime.now()
    robots_url = get_corrected_url(robots_url, "")
    response = get_remote_content(robots_url)

    if response.status_code &lt; 400:
        for ua_item in response.text.split("User-agent:"):
            if ua_item:
                ua_content_items = [
                    ua_split_item.strip()
                    for ua_split_item in ua_item.split("\n")
                    if ua_split_item
                ]
                if not ua_content_items[0].startswith("#"):
                    ua = UserAgent(ua_name=ua_content_items[0])
                    ua.add_allow(
                        [
                            it.split("Allow:")[-1]
                            for it in ua_content_items[1:]
                            if it.startswith("Allow:")
                        ]
                    )
                    ua.add_disallow(
                        [
                            it.split("Disallow:")[-1]
                            for it in ua_content_items[1:]
                            if it.startswith("Disallow:")
                        ]
                    )
                    # TODO: Comments are not included Yet
                    comment = [
                        it.split("# ")[-1]
                        for it in ua_content_items[1:]
                        if it.startswith("#")
                    ]

                    self.add_user_agent(ua=ua)</code></pre>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="pyrobotstxt.RobotsTxt.remove_user_agent" class="doc doc-heading">
          <code class=" language-python">remove_user_agent(ua_name='')</code>

<a href="#pyrobotstxt.RobotsTxt.remove_user_agent" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Remove user agent from RobotsTxt</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>ua_name</code></b>
                  (<code><a class="autorefs autorefs-internal" title="pyrobotstxt.UserAgent" href="../useragent/#pyrobotstxt.UserAgent">UserAgent</a></code>, default:
                      <code>&#39;&#39;</code>
)
              –
              <div class="doc-md-description">
                <p>user agent to be removed from already included in robots.txt file.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary> <code>pyrobotstxt/__init__.py</code></summary>
            <pre class="codehilite"><code class="language-python">def remove_user_agent(self, ua_name=""):
    """Remove user agent from RobotsTxt

    Args:
        ua_name (UserAgent): user agent to be removed from already included in robots.txt file.
    """
    self.user_agents -= [ua for ua in self.user_agents if ua.name == ua_name]</code></pre>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="pyrobotstxt.RobotsTxt.robots_details" class="doc doc-heading">
          <code class=" language-python">robots_details(crawl_bot)</code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#pyrobotstxt.RobotsTxt.robots_details" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Static Method to return details about any crawl bot.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>crawl_bot</code></b>
                  (<code>str</code>)
              –
              <div class="doc-md-description">
                <p>name of crawl bot</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code>dict</code>
            –
            <div class="doc-md-description">
              <p>information about all crawl bots matching to input string.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary> <code>pyrobotstxt/__init__.py</code></summary>
            <pre class="codehilite"><code class="language-python">@staticmethod
def robots_details(crawl_bot):
    """Static Method to return details about any crawl bot.

    Args:
        crawl_bot (str): name of crawl bot

    Returns:
        (dict): information about all crawl bots matching to input string.
    """
    return {
        robot: ROBOTS[robot]
        for robot in ROBOTS
        if crawl_bot.lower() == robot.lower()
    }</code></pre>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="pyrobotstxt.RobotsTxt.robots_name" class="doc doc-heading">
          <code class=" language-python">robots_name(crawl_bot)</code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#pyrobotstxt.RobotsTxt.robots_name" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Find robot name, if you know any keywrod about that crawl bot.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>crawl_bot</code></b>
                  (<code>str</code>)
              –
              <div class="doc-md-description">
                <p>description about the crawl bot. e.g. facebook</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code>dict</code>
            –
            <div class="doc-md-description">
              <p>all matching crawl bots with relevent information</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary> <code>pyrobotstxt/__init__.py</code></summary>
            <pre class="codehilite"><code class="language-python">@staticmethod
def robots_name(crawl_bot):
    """Find robot name, if you know any keywrod about that crawl bot.

    Args:
        crawl_bot (str): description about the crawl bot. e.g. facebook

    Returns:
        (dict): all matching crawl bots with relevent information
    """
    return {
        robot: ROBOTS[robot]
        for robot in ROBOTS
        if crawl_bot.capitalize() in ROBOTS[robot]
    }</code></pre>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="pyrobotstxt.RobotsTxt.write" class="doc doc-heading">
          <code class=" language-python">write(file_path='robots.txt')</code>

<a href="#pyrobotstxt.RobotsTxt.write" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>write robots.txt file at a given file_path location.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>file_path</code></b>
                  (<code>str</code>, default:
                      <code>&#39;robots.txt&#39;</code>
)
              –
              <div class="doc-md-description">
                <p>location of robots.txt file. Defaults to &ldquo;robots.txt&rdquo;.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary> <code>pyrobotstxt/__init__.py</code></summary>
            <pre class="codehilite"><code class="language-python">def write(self, file_path="robots.txt"):
    """write robots.txt file at a given file_path location.

    Args:
        file_path (str, optional): location of robots.txt file. Defaults to "robots.txt".
    """

    with open(file_path, "w") as f:
        # include header
        if self.header:
            f.write(f"# {self.header}")

        # include user agents with consolidate text
        for ua in self.user_agents:
            ua.consolidate()
            f.write(ua.content)

        f.write("\n")

        # append ascii image, if available
        if self.image_branding:
            f.write(self.image_branding)

        # append footer message
        if self.footer:
            f.write(f"\n# {self.footer}")</code></pre>
          </details>
  </div>

</div>



  </div>

  </div>

</div>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../imageasascii/" class="btn btn-neutral float-left" title="ImageAsASCII"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../useragent/" class="btn btn-neutral float-right" title="UserAgent">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
      <p>© Copyright 2022-2023 Faisal Shahzad (seowings.org)</p>
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/serpwings/pyrobotstxt" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../imageasascii/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../useragent/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
